import os
import time
import joblib
import numpy as np
import onnxruntime as ort
import config  # T·ªáp config.py c·ªßa b·∫°n

# ======================================================
# 1. C√ÄI ƒê·∫∂T
# ======================================================
MODEL_DIR = config.MODEL_DIR

# THAY ƒê·ªîI: T√™n t·ªáp pipeline m√† train.py ƒë√£ t·∫°o
PIPELINE_FILENAME = 'onnx_convertible_pipeline.pkl'
PIPELINE_PATH = os.path.join(MODEL_DIR, PIPELINE_FILENAME)

# Ch·ªçn m·ªôt m√¥ h√¨nh ƒë·ªÉ benchmark
TARGET_DAY = config.TARGET_FORECAST_COLS[0] # V√≠ d·ª•: 'target_T+1'
MODEL_NAME = f"{TARGET_DAY}_{config.MODEL_NAME}" # V√≠ d·ª•: 'target_T+1_model_daily'

PKL_PATH = os.path.join(MODEL_DIR, f"{MODEL_NAME}")
ONNX_PATH = os.path.join(MODEL_DIR, f"{MODEL_NAME}.onnx")

# C·∫•u h√¨nh benchmark
N_SAMPLES = 1000  # S·ªë l∆∞·ª£ng m·∫´u trong 1 l√¥
N_ITERATIONS = 100 # Ch·∫°y bao nhi√™u l·∫ßn ƒë·ªÉ l·∫•y trung b√¨nh


# THAY ƒê·ªîI: H√†m n√†y gi·ªëng h·ªát h√†m trong 'convert_to_onnx.py'
def get_num_features_from_pipeline(pipeline_path):
    """
    T·∫£i pipeline ti·ªÅn x·ª≠ l√Ω v√† ƒë·∫øm s·ªë l∆∞·ª£ng features ƒë·∫ßu ra
    t·ª´ b∆∞·ªõc 'preprocess_columns'.
    """
    if not os.path.exists(pipeline_path):
        print(f"‚ùå Error: Pipeline not found at {pipeline_path}")
        print(f"Please run train_linear.py first to create '{PIPELINE_FILENAME}'")
        return None
    
    try:
        # T·∫£i pipeline ƒë·∫ßy ƒë·ªß ( [feature_engineering_pipeline], [scaler] )
        full_preprocessing_pipeline = joblib.load(pipeline_path)
        
        # Truy c·∫≠p v√†o pipeline feature engineering b√™n trong
        feature_pipeline = full_preprocessing_pipeline.named_steps['feature_engineering']
        
        # Truy c·∫≠p v√†o b∆∞·ªõc cu·ªëi c√πng (ColumnPreprocessor)
        preprocessor_step = feature_pipeline.named_steps['preprocess_columns']
        
        # L·∫•y danh s√°ch c·ªôt cu·ªëi c√πng ƒë√£ ƒë∆∞·ª£c 'fit'
        num_features = len(preprocessor_step.final_cols)
        
        print(f"‚úÖ Loaded pipeline. Detected {num_features} output features from ColumnPreprocessor.")
        return num_features
        
    except Exception as e:
        print(f"‚ùå Error loading pipeline or getting feature count: {e}")
        return None

# ======================================================
# 2. T·∫†O D·ªÆ LI·ªÜU ƒê·∫¶U V√ÄO GI·∫¢
# ======================================================
print("üöÄ Starting Benchmark...")
# THAY ƒê·ªîI: S·ª≠ d·ª•ng h√†m m·ªõi
num_features = get_num_features_from_pipeline(PIPELINE_PATH)
if num_features is None:
    exit()

print(f"T·∫°o d·ªØ li·ªáu gi·∫£: ({N_SAMPLES}, {num_features}) features.")
# D·ªØ li·ªáu n√†y gi·∫£ l·∫≠p l√† ƒê√É QUA pipeline v√† scaler
dummy_data = np.random.rand(N_SAMPLES, num_features).astype(np.float32)

# ======================================================
# 3. T·∫¢I C√ÅC MODEL
# ======================================================

print("Loading models...")
# 3a. T·∫£i model Sklearn (.pkl)
try:
    model_sklearn = joblib.load(PKL_PATH)
    print(f"‚úÖ T·∫£i th√†nh c√¥ng {PKL_PATH}")
except Exception as e:
    print(f"‚ùå L·ªói t·∫£i {PKL_PATH}: {e}")
    exit()

# 3b. T·∫£i model ONNX (cho CPU)
try:
    sess_onnx_cpu = ort.InferenceSession(
        ONNX_PATH, 
        providers=['CPUExecutionProvider'] # Ch·ªâ ƒë·ªãnh r√µ ch·∫°y tr√™n CPU
    )
    input_name = sess_onnx_cpu.get_inputs()[0].name
    print(f"‚úÖ T·∫£i th√†nh c√¥ng {ONNX_PATH} cho CPU.")
except Exception as e:
    print(f"‚ùå L·ªói t·∫£i {ONNX_PATH} cho CPU: {e}")
    exit()

# 3c. T·∫£i model ONNX (cho GPU)
sess_onnx_gpu = None
try:
    sess_onnx_gpu = ort.InferenceSession(
        ONNX_PATH, 
        providers=['CUDAExecutionProvider'] # Ch·ªâ ƒë·ªãnh r√µ ch·∫°y tr√™n GPU
    )
    print(f"‚úÖ T·∫£i th√†nh c√¥ng {ONNX_PATH} cho GPU (CUDA).")
except Exception as e:
    print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫£i model cho GPU (CUDA): {e}")
    print("   H√£y ƒë·∫£m b·∫£o b·∫°n ƒë√£ c√†i 'onnxruntime-gpu' v√† c√≥ driver NVIDIA/CUDA.")

# ======================================================
# 4. CH·∫†Y BENCHMARK
# ======================================================
print("\n" + "="*50)
print(f"Ch·∫°y benchmark v·ªõi {N_SAMPLES} m·∫´u, l·∫∑p l·∫°i {N_ITERATIONS} l·∫ßn...")
print("="*50)

# 4a. Benchmark Sklearn (CPU)
start_time = time.perf_counter()
for _ in range(N_ITERATIONS):
    _ = model_sklearn.predict(dummy_data)
end_time = time.perf_counter()
sklearn_time = (end_time - start_time) / N_ITERATIONS
print(f"‚è±Ô∏è Sklearn (CPU) : {sklearn_time * 1000:.6f} ms / l√¥")

# 4b. Benchmark ONNX (CPU)
start_time = time.perf_counter()
for _ in range(N_ITERATIONS):
    _ = sess_onnx_cpu.run(None, {input_name: dummy_data})
end_time = time.perf_counter()
onnx_cpu_time = (end_time - start_time) / N_ITERATIONS
print(f"‚è±Ô∏è ONNX (CPU)    : {onnx_cpu_time * 1000:.6f} ms / l√¥")

# 4c. Benchmark ONNX (GPU)
if sess_onnx_gpu:
    start_time = time.perf_counter()
    for _ in range(N_ITERATIONS):
        _ = sess_onnx_gpu.run(None, {input_name: dummy_data})
    end_time = time.perf_counter()
    onnx_gpu_time = (end_time - start_time) / N_ITERATIONS
    print(f"‚è±Ô∏è ONNX (GPU)    : {onnx_gpu_time * 1000:.6f} ms / l√¥")

# ======================================================
# 5. K·∫æT LU·∫¨N
# ======================================================
print("\n" + "="*50)
print("K·∫øt lu·∫≠n:")
factor_cpu = sklearn_time / onnx_cpu_time
print(f"üéâ ONNX (CPU) nhanh h∆°n Sklearn (CPU) **{factor_cpu:.2f} l·∫ßn**.")

if sess_onnx_gpu:
    factor_gpu = sklearn_time / onnx_gpu_time
    print(f"üéâ ONNX (GPU) nhanh h∆°n Sklearn (CPU) **{factor_gpu:.2f} l·∫ßn**.")