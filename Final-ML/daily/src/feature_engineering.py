# feature_engineering.py
import os
import pandas as pd
import numpy as np
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.pipeline import Pipeline
import config

# ======================================================
# 1. CUSTOM TRANSFORMER CLASSES (ÄÃƒ Sá»¬A)
# ======================================================
class FFillImputer(BaseEstimator, TransformerMixin):
    """Äiá»n NaN báº±ng ffill/bfill, an toÃ n cho time-series."""
    def __init__(self):
        self.num_cols = []

    def fit(self, X, y=None):
        self.num_cols = X.select_dtypes(include=[np.number]).columns
        return self
    
    def transform(self, X):
        df = X.copy()
        if not self.num_cols.empty:
            df[self.num_cols] = df[self.num_cols].ffill().bfill()
        return df
    
class TimeFeatures(BaseEstimator, TransformerMixin):
    """Táº¡o features thá»i gian (cyclical)."""
    def fit(self, X, y=None):
        return self
    
    def transform(self, X):
        df = X.copy()
        df["datetime"] = pd.to_datetime(df["datetime"])
        df["month"] = df["datetime"].dt.month
        df["dayofyear"] = df["datetime"].dt.dayofyear
        df["weekofyear"] = df["datetime"].dt.isocalendar().week
        df["dayofweek"] = df["datetime"].dt.dayofweek
        
        df["sin_dayofyear"] = np.sin(2 * np.pi * df["dayofyear"] / 365.25)
        df["cos_dayofyear"] = np.cos(2 * np.pi * df["dayofyear"] / 365.25)
        df["sin_week"] = np.sin(2 * np.pi * df["weekofyear"] / 52)
        df["cos_week"] = np.cos(2 * np.pi * df["weekofyear"] / 52)
        return df

# ======================================================
# === CLASS NÃ€Y ÄÃƒ ÄÆ¯á»¢C Tá»I Æ¯U HÃ“A Äá»‚ TRÃNH FRAGMENTATION ===
# ======================================================
class LagRollingFeatures(BaseEstimator, TransformerMixin):
    """
    Tá»‘i Æ°u hÃ³a: Táº¡o Rolling (Xu hÆ°á»›ng) vÃ  dÃ¹ng pd.concat
    Ä‘á»ƒ trÃ¡nh bá»‹ "fragmented" (phÃ¢n máº£nh).
    """
    def __init__(self, lag_cols, lags, windows):
        self.lag_cols = lag_cols
        self.lags = lags 
        self.windows = windows
        
    def fit(self, X, y=None):
        return self

    def transform(self, X):
        df = X.copy()
        df = df.sort_values("datetime").reset_index(drop=True) 
        
        # 1. Táº¡o má»™t list rá»—ng Ä‘á»ƒ chá»©a táº¥t cáº£ cÃ¡c feature má»›i
        features_list = []

        for col in self.lag_cols:
            if col in df.columns:
                
                # (VÃ²ng láº·p LAGS Ä‘Ã£ bá»‹ táº¯t)
                for lag in self.lags:
                    df[f"{col}_lag{lag}"] = df[col].shift(lag)

                # Chá»‰ cháº¡y vÃ²ng láº·p Rolling (Xu hÆ°á»›ng)
                for win in self.windows:
                    # DÃ¹ng shift(1) Ä‘á»ƒ trÃ¡nh data leakage
                    rolling_series = df[col].shift(1).rolling(win, min_periods=1)
                    
                    # 2. Táº¡o feature (Series) vÃ  Äáº¶T TÃŠN cho nÃ³
                    roll_mean = rolling_series.mean()
                    roll_mean.name = f"{col}_rollmean{win}"
                    
                    roll_std = rolling_series.std()
                    roll_std.name = f"{col}_rollstd{win}"
                    
                    roll_max = rolling_series.max()
                    roll_max.name = f"{col}_rollmax{win}"
                    
                    roll_min = rolling_series.min()
                    roll_min.name = f"{col}_rollmin{win}"
                    
                    # 3. ThÃªm cÃ¡c feature má»›i vÃ o list
                    features_list.extend([roll_mean, roll_std, roll_max, roll_min])

                    if col in ['precip', 'solarradiation', 'solarenergy', 'snowdepth', 'is_rain']:
                        roll_sum = rolling_series.sum()
                        roll_sum.name = f"{col}_rollsum{win}"
                        features_list.append(roll_sum)
        
        # 4. GhÃ©p (CONCAT) táº¥t cáº£ cÃ¡c feature má»›i Má»˜T Láº¦N
        features_df = pd.concat(features_list, axis=1)
        
        # 5. GhÃ©p DataFrame gá»‘c vá»›i cÃ¡c feature má»›i
        df = pd.concat([df, features_df], axis=1)
        
        return df
# ======================================================
# === Káº¾T THÃšC PHáº¦N Tá»I Æ¯U HÃ“A ===
# ======================================================

# class TextFeatureTransformer(BaseEstimator, TransformerMixin):
#     """
#     Sá»¬A Láº I: Táº¡o feature "hÃ´m qua cÃ³ mÆ°a khÃ´ng"
#     (an toÃ n, khÃ´ng leakage).
#     """
#     def __init__(self):
#         self.text_cols = ['conditions'] # CÃ¡c cá»™t text thÃ´

#     def fit(self, X, y=None):
#         return self
        
#     def transform(self, X):
#         df = X.copy()
#         for col in self.text_cols:
#             if col in df.columns:
#                 # 1. Táº¡o lag1 (dá»¯ liá»‡u text cá»§a hÃ´m qua)
#                 col_lag1 = f"{col}_lag1"
#                 df[col_lag1] = df[col].shift(1).astype(str).str.lower()
                
#                 # 2. Táº¡o feature tá»« lag1
#                 df[f"is_rain_yesterday"] = df[col_lag1].str.contains("rain", na=False).astype(int)
#                 df[f"is_cloudy_yesterday"] = df[col_lag1].str.contains("cloud", na=False).astype(int)
#                 df[f"is_clear_yesterday"] = df[col_lag1].str.contains("clear", na=False).astype(int)
#         return df

class DropRawFeatures(BaseEstimator, TransformerMixin):
    """
    XÃ“A Táº¤T Cáº¢ (29) cá»™t thÃ´ (raw) Ä‘á»ƒ trÃ¡nh data leakage.
    """
    def __init__(self):
        self.raw_cols_to_drop = [
            "temp", "tempmax", "tempmin", "feelslikemax", "feelslikemin", "feelslike",
            "dew", "humidity", "precip", "precipprob", "precipcover",
            "preciptype", "snow", "snowdepth", "windgust", "windspeed", 
            "winddir", "sealevelpressure", "cloudcover", "visibility", 
            "solarradiation", "solarenergy", "uvindex", "severerisk", 
            "sunrise", "sunset", "moonphase", "conditions", "datetime",
            "is_rain", "is_cloudy", "is_clear",
            "stations", "description", "icon", "name"
        ]

    def fit(self, X, y=None):
        return self
    
    def transform(self, X):
        df = X.copy()
        cols_to_drop = list(set([col for col in self.raw_cols_to_drop if col in df.columns]))
        df.drop(columns=cols_to_drop, inplace=True, errors="ignore")
        return df
    
# ======================================================
# 2. FEATURE PIPELINE CREATION FUNCTION (ÄÃ£ sá»­a)
# ======================================================

def create_feature_pipeline():
    """Táº¡o Pipeline cho feature engineering."""
    feature_pipeline = Pipeline([
        ('imputer', FFillImputer()),
        ('time', TimeFeatures()),
        # ('weather_text', TextFeatureTransformer()), 
        ('lags_rolling', LagRollingFeatures( 
            lag_cols=config.LAG_COLS, 
            lags=config.LAGS, 
            windows=config.WINDOWS
        )),
        ('drop_raw', DropRawFeatures()) 
    ])
    return feature_pipeline

# ======================================================
# 3. MAIN PROCESS (Giá»¯ nguyÃªn)
# ======================================================
def main():
    """Cháº¡y quy trÃ¬nh: Concat -> Fit -> Transform -> Split -> Save."""
    print("ğŸš€ Starting Feature Engineering process...")
    
    train_df = pd.read_csv(os.path.join(config.PROCESSED_DATA_DIR, "data_train.csv"))
    val_df = pd.read_csv(os.path.join(config.PROCESSED_DATA_DIR, "data_val.csv"))
    test_df = pd.read_csv(os.path.join(config.PROCESSED_DATA_DIR, "data_test.csv"))
    
    train_len = len(train_df)
    val_len = len(val_df)

    df_full = pd.concat([train_df, val_df, test_df], ignore_index=True)
    df_full["datetime"] = pd.to_datetime(df_full["datetime"])
    df_full = df_full.sort_values("datetime").reset_index(drop=True)

    feature_pipeline = create_feature_pipeline()
    
    print("âš™ï¸ Applying feature engineering pipeline to full dataset...")
    feature_pipeline.fit(train_df)
    df_full_feat = feature_pipeline.transform(df_full)
    
    train_feat = df_full_feat.iloc[:train_len]
    val_feat = df_full_feat.iloc[train_len : train_len + val_len]
    test_feat = df_full_feat.iloc[train_len + val_len :]

    train_feat = train_feat.dropna().reset_index(drop=True)
    val_feat = val_feat.reset_index(drop=True)
    test_feat = test_feat.reset_index(drop=True)

    print(f"ğŸ“Š Shape after feature creation: Train={train_feat.shape}, Val={val_feat.shape}, Test={test_feat.shape}")

    train_path = os.path.join(config.FEATURE_DIR, "feature_train.csv")
    val_path = os.path.join(config.FEATURE_DIR, "feature_val.csv")
    test_path = os.path.join(config.FEATURE_DIR, "feature_test.csv")

    train_feat.to_csv(train_path, index=False)
    val_feat.to_csv(val_path, index=False)
    test_feat.to_csv(test_path, index=False)
    
    print(f"""
âœ… Feature data saved:
  â”£â” Train: {train_path}
  â”£â” Val:   {val_path}
  â”—â” Test:  {test_path}
""")

if __name__ == "__main__":
    main()