import os
import pandas as pd
import numpy as np
import yaml
import matplotlib.pyplot as plt
import seaborn as sns
import config
import sys

# (H√†m load_one_metric_file v√† load_all_metrics gi·ªØ nguy√™n nh∆∞ c≈©)

def load_one_metric_file(filepath, model_type, metric_type):
    """
    H√†m helper: T·∫£i 1 file YAML, chuy·ªÉn th√†nh DF, v√† th√™m c·ªôt
    """
    if not os.path.exists(filepath):
        print(f"‚ùå C·∫¢NH B√ÅO: Kh√¥ng t√¨m th·∫•y file metrics: {filepath}")
        print("   H√£y ch·∫°y file train/inference t∆∞∆°ng ·ª©ng tr∆∞·ªõc.")
        return None
    
    try:
        with open(filepath, 'r') as f:
            data = yaml.safe_load(f)
        
        df = pd.DataFrame.from_dict(data, orient='index')
        df['model_type'] = model_type
        df['metric_type'] = metric_type
        
        # Chuy·ªÉn 'target_t24', 'target_t48' -> 1, 2, 3... (Ng√†y)
        horizon_hours = df.index.str.replace('target_t', '').astype(int)
        df['Horizon'] = horizon_hours / 24
        
        return df
    except Exception as e:
        print(f"‚ùå L·ªói khi ƒë·ªçc file {filepath}: {e}")
        return None

def load_all_metrics():
    """
    T·∫£i T·∫§T C·∫¢ 6 file metrics (Train/Test c·ªßa 3 m√¥ h√¨nh)
    """
    all_dfs = []
    
    # === 1. T·∫£i m√¥ h√¨nh Linear ===
    all_dfs.append(load_one_metric_file(
        os.path.join(config.OUTPUT_DIR, config.TRAIN_METRICS_LINEAR_NAME),
        'Linear', 'Train'
    ))
    all_dfs.append(load_one_metric_file(
        os.path.join(config.OUTPUT_DIR, config.TEST_METRICS_LINEAR_NAME),
        'Linear', 'Test'
    ))
    
    # === 2. T·∫£i m√¥ h√¨nh XGBoost ===
    all_dfs.append(load_one_metric_file(
        os.path.join(config.OUTPUT_DIR, config.TRAIN_METRICS_XGBOOST_NAME),
        'XGBoost', 'Train'
    ))
    all_dfs.append(load_one_metric_file(
        os.path.join(config.OUTPUT_DIR, config.TEST_METRICS_XGBOOST_NAME),
        'XGBoost', 'Test'
    ))
    
    # === 3. T·∫£i m√¥ h√¨nh LightGBM ===
    all_dfs.append(load_one_metric_file(
        os.path.join(config.OUTPUT_DIR, config.TRAIN_METRICS_LIGHTGBM_NAME),
        'LightGBM', 'Train'
    ))
    all_dfs.append(load_one_metric_file(
        os.path.join(config.OUTPUT_DIR, config.TEST_METRICS_LIGHTGBM_NAME),
        'LightGBM', 'Test'
    ))
    
    # Ki·ªÉm tra n·∫øu c√≥ file n√†o b·ªã thi·∫øu
    if any(df is None for df in all_dfs):
        print("\nM·ªôt ho·∫∑c nhi·ªÅu file metrics b·ªã thi·∫øu. D·ª´ng ch∆∞∆°ng tr√¨nh.")
        return None
        
    # G·ªôp t·∫•t c·∫£ l·∫°i
    full_df = pd.concat(all_dfs)
    
    print("‚úÖ ƒê√£ t·∫£i v√† g·ªôp th√†nh c√¥ng 6 file metrics.")
    return full_df

# ===================================================================
# C√ÅC H√ÄM V·∫º BI·ªÇU ƒê·ªí (ƒê√É C·∫¨P NH·∫¨T)
# ===================================================================

def plot_test_metric_comparison(df_test_only, metric_name, title, ylabel, filename, higher_is_better=False):
    """
    H√†m chung ƒë·ªÉ v·∫Ω 3 m√¥ h√¨nh cho 1 ch·ªâ s·ªë Test (RMSE, MAE, R2)
    """
    plt.figure(figsize=(10, 6))
    sns.set_style("whitegrid")
    
    # S·∫Øp x·∫øp legend theo hi·ªáu su·∫•t
    sorted_models = df_test_only.groupby('model_type')[metric_name].mean().sort_values(ascending=higher_is_better).index
    
    sns.lineplot(
        data=df_test_only,
        x='Horizon',
        y=metric_name,
        hue='model_type', # 3 m√†u cho 3 m√¥ h√¨nh
        hue_order=sorted_models, # S·∫Øp x·∫øp legend
        style='model_type', # 3 ki·ªÉu ƒë∆∞·ªùng cho 3 m√¥ h√¨nh
        style_order=sorted_models,
        markers=True,
        linewidth=2.5,
        markersize=8
    )
    
    plt.title(title, fontsize=16, fontweight='bold')
    plt.xlabel('Ng√†y d·ª± b√°o (T+N)', fontsize=12)
    plt.ylabel(ylabel, fontsize=12)
    plt.xticks(range(1, 8)) # 1, 2, ... 7
    plt.legend(title="M√¥ h√¨nh (T·ªët nh·∫•t -> K√©m nh·∫•t)")
    plt.grid(True, alpha=0.7)

    plot_path = os.path.join(config.OUTPUT_DIR, filename)
    plt.savefig(plot_path, dpi=120)
    print(f"üíæ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì: {plot_path}")

def plot_overfitting_comparison(df):
    """
    Bi·ªÉu ƒë·ªì 4: So s√°nh ƒë·ªô Overfitting (Gap) c·ªßa 3 m√¥ h√¨nh
    """
    # 1. Pivot data ƒë·ªÉ c√≥ Train/Test tr√™n c√πng 1 h√†ng
    df_pivot = df.pivot_table(
        index=['Horizon', 'model_type'], 
        columns='metric_type', 
        values='RMSE' # V·∫´n d√πng RMSE l√†m g·ªëc
    ).reset_index()
    
    # 2. T√≠nh to√°n Gap
    df_pivot['Gap (%)'] = (df_pivot['Test'] - df_pivot['Train']) / df_pivot['Train'] * 100
    
    plt.figure(figsize=(10, 6))
    sns.set_style("whitegrid")
    
    # 3. V·∫Ω bi·ªÉu ƒë·ªì Gap
    sns.lineplot(
        data=df_pivot,
        x='Horizon',
        y='Gap (%)',
        hue='model_type',
        style='model_type',
        markers=True,
        linewidth=2.5,
        markersize=8
    )
    
    plt.title('So s√°nh Overfitting (Train-Test RMSE Gap) 3 M√¥ h√¨nh (Hourly)', fontsize=16, fontweight='bold')
    plt.xlabel('Ng√†y d·ª± b√°o (T+N)', fontsize=12)
    plt.ylabel('Overfitting (Gap %)', fontsize=12)
    plt.xticks(range(1, 8))
    plt.legend(title="M√¥ h√¨nh")
    plt.axhline(0, color='black', linestyle='--', linewidth=1) # ƒê∆∞·ªùng 0%
    plt.grid(True, alpha=0.7)

    plot_path = os.path.join(config.OUTPUT_DIR, 'compare_ALL_MODELS_Overfitting_Gap.png')
    plt.savefig(plot_path, dpi=120)
    print(f"üíæ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì Overfitting Gap: {plot_path}")

def main():
    # Load t·∫•t c·∫£ 6 file
    df_full_metrics = load_all_metrics()
    
    if df_full_metrics is not None:
        # L·ªçc ra data Test ƒë·ªÉ t√°i s·ª≠ d·ª•ng
        df_test_only = df_full_metrics[df_full_metrics['metric_type'] == 'Test'].copy()

        # === V·∫º 4 BI·ªÇU ƒê·ªí ===
        
        # 1. Bi·ªÉu ƒë·ªì RMSE (L·ªói tuy·ªát ƒë·ªëi)
        plot_test_metric_comparison(
            df_test_only,
            metric_name='RMSE',
            title='So s√°nh Hi·ªáu su·∫•t (Test RMSE) 3 M√¥ h√¨nh (Hourly)',
            ylabel='RMSE (L·ªói nhi·ªát ƒë·ªô ¬∞C)',
            filename='compare_ALL_MODELS_Test_RMSE.png',
            higher_is_better=False # RMSE: C√†ng th·∫•p c√†ng t·ªët
        )
        
        # 2. Bi·ªÉu ƒë·ªì R2 (ƒê·ªô "fit")
        plot_test_metric_comparison(
            df_test_only,
            metric_name='R2',
            title='So s√°nh ƒê·ªô "Fit" (Test R2) 3 M√¥ h√¨nh (Hourly)',
            ylabel='R-Squared (R¬≤)',
            filename='compare_ALL_MODELS_Test_R2.png',
            higher_is_better=True # R2: C√†ng cao c√†ng t·ªët
        )
        
        # 3. Bi·ªÉu ƒë·ªì MAE (L·ªói tuy·ªát ƒë·ªëi)
        plot_test_metric_comparison(
            df_test_only,
            metric_name='MAE',
            title='So s√°nh Hi·ªáu su·∫•t (Test MAE) 3 M√¥ h√¨nh (Hourly)',
            ylabel='MAE (L·ªói nhi·ªát ƒë·ªô ¬∞C)',
            filename='compare_ALL_MODELS_Test_MAE.png',
            higher_is_better=False # MAE: C√†ng th·∫•p c√†ng t·ªët
        )
        
        # 4. Bi·ªÉu ƒë·ªì Overfitting (D√πng df_full_metrics)
        plot_overfitting_comparison(df_full_metrics)
        
        print("\nüéâ HO√ÄN T·∫§T TR·ª∞C QUAN H√ìA SO S√ÅNH 3 M√î H√åNH!")
        print(f"Xem 4 file .png trong: {config.OUTPUT_DIR}")

if __name__ == "__main__":
    # Dependency checks
    try:
        import yaml
    except ImportError:
        print("\nERROR: Missing 'PyYAML' library.")
        print("Please run: pip install pyyaml\n")
        sys.exit(1)
        
    try:
        import seaborn as sns
    except ImportError:
        print("\nERROR: Missing 'seaborn' library.")
        print("Please run: pip install seaborn\n")
        sys.exit(1)
        
    main()