{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16e7a44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî ƒê√£ l∆∞u: optuna_best_params_xgboost_hourly.yaml\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# Check if study object exists, otherwise create a placeholder or load from existing params\n",
    "if 'study' in locals():\n",
    "    best_params = study.best_params\n",
    "elif 'params' in locals():\n",
    "    best_params = params\n",
    "else:\n",
    "    print(\"Warning: Neither 'study' nor 'params' found. Please run the Optuna optimization first.\")\n",
    "    best_params = {}\n",
    "\n",
    "# Save to YAML file\n",
    "file_name = \"optuna_best_params_xgboost_hourly.yaml\"\n",
    "with open(file_name, \"w\") as f:\n",
    "    yaml.dump(best_params, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(\"‚úî ƒê√£ l∆∞u:\", file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f15f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import skl2onnx\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "import numpy as np\n",
    "\n",
    "# 1Ô∏è‚É£ T√¨m m√¥ h√¨nh t·ª´ th∆∞ m·ª•c hi·ªán t·∫°i ho·∫∑c th∆∞ m·ª•c models\n",
    "model_path = None\n",
    "model_filename = None\n",
    "\n",
    "# T√¨m file .pkl ho·∫∑c .joblib trong th∆∞ m·ª•c hi·ªán t·∫°i v√† th∆∞ m·ª•c cha\n",
    "search_dirs = [\n",
    "    \".\",\n",
    "    \"..\",\n",
    "    \"../models\",\n",
    "    \"../daily/models\"\n",
    "]\n",
    "\n",
    "for search_dir in search_dirs:\n",
    "    if os.path.exists(search_dir):\n",
    "        for file in os.listdir(search_dir):\n",
    "            if file.endswith(('.pkl', '.joblib')) and 'model' in file.lower():\n",
    "                model_path = os.path.join(search_dir, file)\n",
    "                model_filename = file\n",
    "                break\n",
    "    if model_path:\n",
    "        break\n",
    "\n",
    "if model_path and os.path.exists(model_path):\n",
    "    print(f\"‚úÖ T√¨m th·∫•y m√¥ h√¨nh: {model_path}\")\n",
    "    \n",
    "    # 2Ô∏è‚É£ Load m√¥ h√¨nh\n",
    "    model = joblib.load(model_path)\n",
    "    print(f\"‚úÖ ƒê√£ t·∫£i m√¥ h√¨nh: {model}\")\n",
    "    \n",
    "    # 3Ô∏è‚É£ Chuy·ªÉn ƒë·ªïi sang ONNX\n",
    "    try:\n",
    "        # ƒê·ªãnh nghƒ©a input type (gi·∫£ s·ª≠ m√¥ h√¨nh nh·∫≠n vector ƒë·∫∑c tr∆∞ng)\n",
    "        initial_type = [('float_input', FloatTensorType([None, 10]))]  # Thay 10 b·∫±ng s·ªë ƒë·∫∑c tr∆∞ng th·ª±c t·∫ø\n",
    "        \n",
    "        # Chuy·ªÉn ƒë·ªïi\n",
    "        onnx_model = skl2onnx.convert_sklearn(model, initial_types=initial_type)\n",
    "        \n",
    "        # L∆∞u file ONNX\n",
    "        output_path = model_filename.replace('.pkl', '.onnx').replace('.joblib', '.onnx')\n",
    "        with open(output_path, 'wb') as f:\n",
    "            f.write(onnx_model.SerializeToString())\n",
    "        \n",
    "        print(f\"‚úÖ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c export sang ONNX: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è L·ªói khi chuy·ªÉn ƒë·ªïi sang ONNX: {e}\")\n",
    "        print(\"üí° G·ª£i √Ω: N·∫øu m√¥ h√¨nh l√† LightGBM, XGBoost, ho·∫∑c CatBoost, h√£y s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p chuy√™n bi·ªát cho t·ª´ng th∆∞ vi·ªán\")\n",
    "else:\n",
    "    print(\"‚ùå Kh√¥ng t√¨m th·∫•y file m√¥ h√¨nh (.pkl ho·∫∑c .joblib) trong c√°c th∆∞ m·ª•c t√¨m ki·∫øm\")\n",
    "    print(f\"üìÅ C√°c th∆∞ m·ª•c t√¨m ki·∫øm: {search_dirs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21656666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== XU·∫§T M√î H√åNH ONNX CHO XGBoost/LightGBM ====================\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Ph∆∞∆°ng ph√°p 1: D√πng skl2onnx (cho c√°c m√¥ h√¨nh scikit-learn)\n",
    "try:\n",
    "    import skl2onnx\n",
    "    from skl2onnx.common.data_types import FloatTensorType\n",
    "    \n",
    "    # T√¨m m√¥ h√¨nh XGBoost ho·∫∑c LightGBM\n",
    "    model_path = None\n",
    "    for search_dir in [\".\", \"..\", \"../models\", \"../daily/models\"]:\n",
    "        if os.path.exists(search_dir):\n",
    "            for file in os.listdir(search_dir):\n",
    "                if (\"xgboost\" in file.lower() or \"lgb\" in file.lower() or \"lightgbm\" in file.lower()) and file.endswith(('.pkl', '.joblib')):\n",
    "                    model_path = os.path.join(search_dir, file)\n",
    "                    break\n",
    "        if model_path:\n",
    "            break\n",
    "    \n",
    "    if model_path:\n",
    "        model = joblib.load(model_path)\n",
    "        print(f\"‚úÖ T·∫£i m√¥ h√¨nh: {model_path}\")\n",
    "        \n",
    "        # S·ªë features c·∫ßn ph√π h·ª£p v·ªõi m√¥ h√¨nh c·ªßa b·∫°n\n",
    "        initial_type = [('float_input', FloatTensorType([None, 10]))]\n",
    "        onnx_model = skl2onnx.convert_sklearn(model, initial_types=initial_type)\n",
    "        \n",
    "        output_path = model_path.replace('.pkl', '.onnx').replace('.joblib', '.onnx')\n",
    "        with open(output_path, 'wb') as f:\n",
    "            f.write(onnx_model.SerializeToString())\n",
    "        \n",
    "        print(f\"‚úÖ Xu·∫•t ONNX th√†nh c√¥ng: {output_path}\")\n",
    "    else:\n",
    "        print(\"‚ùå Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh XGBoost/LightGBM\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Ph∆∞∆°ng ph√°p skl2onnx th·∫•t b·∫°i: {e}\")\n",
    "\n",
    "# Ph∆∞∆°ng ph√°p 2: D√πng onnx-converter-common cho XGBoost\n",
    "print(\"\\n--- Ph∆∞∆°ng ph√°p 2: D√πng onnxmltools ---\")\n",
    "try:\n",
    "    import onnxmltools\n",
    "    import xgboost as xgb\n",
    "    \n",
    "    # T√¨m m√¥ h√¨nh XGBoost\n",
    "    model_path = None\n",
    "    for search_dir in [\".\", \"..\", \"../models\", \"../daily/models\"]:\n",
    "        if os.path.exists(search_dir):\n",
    "            for file in os.listdir(search_dir):\n",
    "                if \"xgboost\" in file.lower() and file.endswith(('.pkl', '.joblib', '.json')):\n",
    "                    model_path = os.path.join(search_dir, file)\n",
    "                    break\n",
    "        if model_path:\n",
    "            break\n",
    "    \n",
    "    if model_path:\n",
    "        model = joblib.load(model_path)\n",
    "        print(f\"‚úÖ T·∫£i m√¥ h√¨nh XGBoost: {model_path}\")\n",
    "        \n",
    "        # Chuy·ªÉn ƒë·ªïi XGBoost sang ONNX\n",
    "        onnx_model = onnxmltools.convert_xgboost(model)\n",
    "        \n",
    "        output_path = model_path.replace('.pkl', '.onnx').replace('.joblib', '.onnx')\n",
    "        onnxmltools.utils.save_model(onnx_model, output_path)\n",
    "        \n",
    "        print(f\"‚úÖ Xu·∫•t ONNX th√†nh c√¥ng: {output_path}\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh XGBoost\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Ph∆∞∆°ng ph√°p onnxmltools th·∫•t b·∫°i: {e}\")\n",
    "\n",
    "# Ph∆∞∆°ng ph√°p 3: D√πng skl2onnx cho LightGBM\n",
    "print(\"\\n--- Ph∆∞∆°ng ph√°p 3: LightGBM v·ªõi skl2onnx ---\")\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    from skl2onnx.common.data_types import FloatTensorType\n",
    "    import skl2onnx\n",
    "    \n",
    "    # T√¨m m√¥ h√¨nh LightGBM\n",
    "    model_path = None\n",
    "    for search_dir in [\".\", \"..\", \"../models\", \"../daily/models\"]:\n",
    "        if os.path.exists(search_dir):\n",
    "            for file in os.listdir(search_dir):\n",
    "                if (\"lgb\" in file.lower() or \"lightgbm\" in file.lower()) and file.endswith(('.pkl', '.joblib')):\n",
    "                    model_path = os.path.join(search_dir, file)\n",
    "                    break\n",
    "        if model_path:\n",
    "            break\n",
    "    \n",
    "    if model_path:\n",
    "        model = joblib.load(model_path)\n",
    "        print(f\"‚úÖ T·∫£i m√¥ h√¨nh LightGBM: {model_path}\")\n",
    "        \n",
    "        # Chuy·ªÉn ƒë·ªïi LightGBM sang ONNX\n",
    "        initial_type = [('float_input', FloatTensorType([None, 10]))]\n",
    "        onnx_model = skl2onnx.convert_sklearn(model, initial_types=initial_type)\n",
    "        \n",
    "        output_path = model_path.replace('.pkl', '.onnx').replace('.joblib', '.onnx')\n",
    "        with open(output_path, 'wb') as f:\n",
    "            f.write(onnx_model.SerializeToString())\n",
    "        \n",
    "        print(f\"‚úÖ Xu·∫•t ONNX th√†nh c√¥ng: {output_path}\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh LightGBM\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Ph∆∞∆°ng ph√°p LightGBM th·∫•t b·∫°i: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"‚úÖ Ho√†n th√†nh xu·∫•t m√¥ h√¨nh sang ONNX!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b8b2db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
