{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e7a44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\this pc\\Downloads\\Final-ML\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Import thÃ nh cÃ´ng!\n",
      "\n",
      "ğŸ“Š Äang táº£i dá»¯ liá»‡u...\n",
      "âœ… Train shape: (66103, 31)\n",
      "âœ… Val shape: (14165, 31)\n",
      "âœ… Test shape: (14166, 31)\n",
      "âœ… Train shape: (66103, 31)\n",
      "âœ… Val shape: (14165, 31)\n",
      "âœ… Test shape: (14166, 31)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from optuna.trial import Trial\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Import thÃ nh cÃ´ng!\")\n",
    "\n",
    "# 1ï¸âƒ£ Load dá»¯ liá»‡u\n",
    "print(\"\\nğŸ“Š Äang táº£i dá»¯ liá»‡u...\")\n",
    "data_dir = \"../processed_data\"  # Thay Ä‘á»•i Ä‘Æ°á»ng dáº«n náº¿u cáº§n\n",
    "\n",
    "try:\n",
    "    X_train = pd.read_csv(f\"{data_dir}/data_train.csv\")\n",
    "    X_val = pd.read_csv(f\"{data_dir}/data_val.csv\")\n",
    "    X_test = pd.read_csv(f\"{data_dir}/data_test.csv\")\n",
    "    \n",
    "    # TÃ¡ch features vÃ  target\n",
    "    y_train = X_train.iloc[:, -1]\n",
    "    X_train = X_train.iloc[:, :-1]\n",
    "    \n",
    "    y_val = X_val.iloc[:, -1]\n",
    "    X_val = X_val.iloc[:, :-1]\n",
    "    \n",
    "    y_test = X_test.iloc[:, -1]\n",
    "    X_test = X_test.iloc[:, :-1]\n",
    "    \n",
    "    # â­ LOáº I Bá» CÃC Cá»˜T NON-NUMERIC\n",
    "    print(\"ğŸ” Loáº¡i bá» cÃ¡c cá»™t khÃ´ng pháº£i sá»‘...\")\n",
    "    numeric_cols = X_train.select_dtypes(include=[np.number]).columns\n",
    "    X_train = X_train[numeric_cols].astype(np.float32)\n",
    "    X_val = X_val[numeric_cols].astype(np.float32)\n",
    "    X_test = X_test[numeric_cols].astype(np.float32)\n",
    "    \n",
    "    # Convert target to float\n",
    "    y_train = y_train.astype(np.float32)\n",
    "    y_val = y_val.astype(np.float32)\n",
    "    y_test = y_test.astype(np.float32)\n",
    "    \n",
    "    # Xá»­ lÃ½ NaN values\n",
    "    X_train = X_train.fillna(0)\n",
    "    X_val = X_val.fillna(0)\n",
    "    X_test = X_test.fillna(0)\n",
    "    \n",
    "    y_train = y_train.fillna(0)\n",
    "    y_val = y_val.fillna(0)\n",
    "    y_test = y_test.fillna(0)\n",
    "    \n",
    "    print(f\"âœ… Train shape: {X_train.shape}\")\n",
    "    print(f\"âœ… Val shape: {X_val.shape}\")\n",
    "    print(f\"âœ… Test shape: {X_test.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Lá»—i táº£i dá»¯ liá»‡u: {e}\")\n",
    "    print(\"ğŸ’¡ Táº¡o dá»¯ liá»‡u giáº£ Ä‘á»‹nh cho demo...\")\n",
    "    \n",
    "    # Táº¡o dá»¯ liá»‡u giáº£ Ä‘á»‹nh\n",
    "    from sklearn.datasets import make_regression\n",
    "    X, y = make_regression(n_samples=1000, n_features=20, noise=10, random_state=42)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "    \n",
    "    X_train = pd.DataFrame(X_train, columns=[f'feature_{i}' for i in range(X.shape[1])])\n",
    "    X_val = pd.DataFrame(X_val, columns=[f'feature_{i}' for i in range(X.shape[1])])\n",
    "    X_test = pd.DataFrame(X_test, columns=[f'feature_{i}' for i in range(X.shape[1])])\n",
    "    y_train = pd.Series(y_train)\n",
    "    y_val = pd.Series(y_val)\n",
    "    y_test = pd.Series(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318b4e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 20:59:18,365] A new study created in memory with name: no-name-d0465f36-11a0-45ab-995b-e2b0ba2b37e9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ”§ Báº®T Äáº¦U TUNING HYPERPARAMETERS LIGHTGBM Vá»šI OPTUNA\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Báº¯t Ä‘áº§u tuning vá»›i 50 trials...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-16 20:59:18,371] Trial 0 failed with parameters: {'num_leaves': 69, 'max_depth': 15, 'learning_rate': 0.1205712628744377, 'min_child_samples': 32, 'subsample': 0.5780093202212182, 'colsample_bytree': 0.5779972601681014, 'reg_alpha': 0.05808361216819946, 'reg_lambda': 0.8661761457749352, 'min_split_gain': 0.06011150117432088} because of the following error: ValueError('pandas dtypes must be int, float or bool.\\nFields with bad pandas dtypes: datetime: object, name: object, datetime.1: object, preciptype: object, conditions: object, icon: object, stations: object').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\this pc\\Downloads\\Final-ML\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\this pc\\AppData\\Local\\Temp\\ipykernel_6636\\3985308511.py\", line 103, in objective\n",
      "    model = lgb.train(\n",
      "        params,\n",
      "    ...<6 lines>...\n",
      "        ]\n",
      "    )\n",
      "  File \"c:\\Users\\this pc\\Downloads\\Final-ML\\.venv\\Lib\\site-packages\\lightgbm\\engine.py\", line 297, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"c:\\Users\\this pc\\Downloads\\Final-ML\\.venv\\Lib\\site-packages\\lightgbm\\basic.py\", line 3656, in __init__\n",
      "    train_set.construct()\n",
      "    ~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\this pc\\Downloads\\Final-ML\\.venv\\Lib\\site-packages\\lightgbm\\basic.py\", line 2590, in construct\n",
      "    self._lazy_init(\n",
      "    ~~~~~~~~~~~~~~~^\n",
      "        data=self.data,\n",
      "        ^^^^^^^^^^^^^^^\n",
      "    ...<9 lines>...\n",
      "        position=self.position,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\this pc\\Downloads\\Final-ML\\.venv\\Lib\\site-packages\\lightgbm\\basic.py\", line 2123, in _lazy_init\n",
      "    data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(\n",
      "                                                                       ~~~~~~~~~~~~~~~~~^\n",
      "        data=data,\n",
      "        ^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "        pandas_categorical=self.pandas_categorical,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\this pc\\Downloads\\Final-ML\\.venv\\Lib\\site-packages\\lightgbm\\basic.py\", line 868, in _data_from_pandas\n",
      "    _pandas_to_numpy(data, target_dtype=target_dtype),\n",
      "    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\this pc\\Downloads\\Final-ML\\.venv\\Lib\\site-packages\\lightgbm\\basic.py\", line 814, in _pandas_to_numpy\n",
      "    _check_for_bad_pandas_dtypes(data.dtypes)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\this pc\\Downloads\\Final-ML\\.venv\\Lib\\site-packages\\lightgbm\\basic.py\", line 805, in _check_for_bad_pandas_dtypes\n",
      "    raise ValueError(\n",
      "        f\"pandas dtypes must be int, float or bool.\\nFields with bad pandas dtypes: {', '.join(bad_pandas_dtypes)}\"\n",
      "    )\n",
      "ValueError: pandas dtypes must be int, float or bool.\n",
      "Fields with bad pandas dtypes: datetime: object, name: object, datetime.1: object, preciptype: object, conditions: object, icon: object, stations: object\n",
      "[W 2025-11-16 20:59:18,379] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "pandas dtypes must be int, float or bool.\nFields with bad pandas dtypes: datetime: object, name: object, datetime.1: object, preciptype: object, conditions: object, icon: object, stations: object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 128\u001b[39m\n\u001b[32m    122\u001b[39m study = optuna.create_study(\n\u001b[32m    123\u001b[39m     direction=\u001b[33m'\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    124\u001b[39m     sampler=optuna.samplers.TPESampler(seed=\u001b[32m42\u001b[39m)\n\u001b[32m    125\u001b[39m )\n\u001b[32m    127\u001b[39m \u001b[38;5;66;03m# Cháº¡y optimization (giáº£m xuá»‘ng 50 trials Ä‘á»ƒ nhanh hÆ¡n)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[38;5;66;03m# 3ï¸âƒ£ Hiá»ƒn thá»‹ káº¿t quáº£\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\this pc\\Downloads\\Final-ML\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\this pc\\Downloads\\Final-ML\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:67\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\this pc\\Downloads\\Final-ML\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:164\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\this pc\\Downloads\\Final-ML\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:262\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    258\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    259\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    261\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\this pc\\Downloads\\Final-ML\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:205\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    207\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    208\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 103\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m    100\u001b[39m train_data = lgb.Dataset(X_train, label=y_train)\n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m# Train model vá»›i early stopping\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m model = \u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperiod\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Táº¯t log\u001b[39;49;00m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# ÄÃ¡nh giÃ¡ trÃªn validation set\u001b[39;00m\n\u001b[32m    115\u001b[39m y_pred = model.predict(X_val)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\this pc\\Downloads\\Final-ML\\.venv\\Lib\\site-packages\\lightgbm\\engine.py:297\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     booster = \u001b[43mBooster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[32m    299\u001b[39m         booster.set_train_data_name(train_data_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\this pc\\Downloads\\Final-ML\\.venv\\Lib\\site-packages\\lightgbm\\basic.py:3656\u001b[39m, in \u001b[36mBooster.__init__\u001b[39m\u001b[34m(self, params, train_set, model_file, model_str)\u001b[39m\n\u001b[32m   3649\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_network(\n\u001b[32m   3650\u001b[39m         machines=machines,\n\u001b[32m   3651\u001b[39m         local_listen_port=params[\u001b[33m\"\u001b[39m\u001b[33mlocal_listen_port\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   3652\u001b[39m         listen_time_out=params.get(\u001b[33m\"\u001b[39m\u001b[33mtime_out\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m120\u001b[39m),\n\u001b[32m   3653\u001b[39m         num_machines=params[\u001b[33m\"\u001b[39m\u001b[33mnum_machines\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   3654\u001b[39m     )\n\u001b[32m   3655\u001b[39m \u001b[38;5;66;03m# construct booster object\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3656\u001b[39m \u001b[43mtrain_set\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3657\u001b[39m \u001b[38;5;66;03m# copy the parameters from train_set\u001b[39;00m\n\u001b[32m   3658\u001b[39m params.update(train_set.get_params())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\this pc\\Downloads\\Final-ML\\.venv\\Lib\\site-packages\\lightgbm\\basic.py:2590\u001b[39m, in \u001b[36mDataset.construct\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2585\u001b[39m             \u001b[38;5;28mself\u001b[39m._set_init_score_by_predictor(\n\u001b[32m   2586\u001b[39m                 predictor=\u001b[38;5;28mself\u001b[39m._predictor, data=\u001b[38;5;28mself\u001b[39m.data, used_indices=used_indices\n\u001b[32m   2587\u001b[39m             )\n\u001b[32m   2588\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2589\u001b[39m     \u001b[38;5;66;03m# create train\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2590\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2591\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2592\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2593\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreference\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2594\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2595\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2596\u001b[39m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2597\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2600\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.free_raw_data:\n\u001b[32m   2604\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\this pc\\Downloads\\Final-ML\\.venv\\Lib\\site-packages\\lightgbm\\basic.py:2123\u001b[39m, in \u001b[36mDataset._lazy_init\u001b[39m\u001b[34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params, position)\u001b[39m\n\u001b[32m   2121\u001b[39m     categorical_feature = reference.categorical_feature\n\u001b[32m   2122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd_DataFrame):\n\u001b[32m-> \u001b[39m\u001b[32m2123\u001b[39m     data, feature_name, categorical_feature, \u001b[38;5;28mself\u001b[39m.pandas_categorical = \u001b[43m_data_from_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2124\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2125\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2127\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpandas_categorical\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpandas_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2128\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2129\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m _is_pyarrow_table(data) \u001b[38;5;129;01mand\u001b[39;00m feature_name == \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2130\u001b[39m     feature_name = data.column_names\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\this pc\\Downloads\\Final-ML\\.venv\\Lib\\site-packages\\lightgbm\\basic.py:868\u001b[39m, in \u001b[36m_data_from_pandas\u001b[39m\u001b[34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[39m\n\u001b[32m    864\u001b[39m df_dtypes.append(np.float32)\n\u001b[32m    865\u001b[39m target_dtype = np.result_type(*df_dtypes)\n\u001b[32m    867\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m868\u001b[39m     \u001b[43m_pandas_to_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_dtype\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    869\u001b[39m     feature_name,\n\u001b[32m    870\u001b[39m     categorical_feature,\n\u001b[32m    871\u001b[39m     pandas_categorical,\n\u001b[32m    872\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\this pc\\Downloads\\Final-ML\\.venv\\Lib\\site-packages\\lightgbm\\basic.py:814\u001b[39m, in \u001b[36m_pandas_to_numpy\u001b[39m\u001b[34m(data, target_dtype)\u001b[39m\n\u001b[32m    810\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_pandas_to_numpy\u001b[39m(\n\u001b[32m    811\u001b[39m     data: pd_DataFrame,\n\u001b[32m    812\u001b[39m     target_dtype: \u001b[33m\"\u001b[39m\u001b[33mnp.typing.DTypeLike\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    813\u001b[39m ) -> np.ndarray:\n\u001b[32m--> \u001b[39m\u001b[32m814\u001b[39m     \u001b[43m_check_for_bad_pandas_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    815\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    816\u001b[39m         \u001b[38;5;66;03m# most common case (no nullable dtypes)\u001b[39;00m\n\u001b[32m    817\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m data.to_numpy(dtype=target_dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\this pc\\Downloads\\Final-ML\\.venv\\Lib\\site-packages\\lightgbm\\basic.py:805\u001b[39m, in \u001b[36m_check_for_bad_pandas_dtypes\u001b[39m\u001b[34m(pandas_dtypes_series)\u001b[39m\n\u001b[32m    799\u001b[39m bad_pandas_dtypes = [\n\u001b[32m    800\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpandas_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    801\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m column_name, pandas_dtype \u001b[38;5;129;01min\u001b[39;00m pandas_dtypes_series.items()\n\u001b[32m    802\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_allowed_numpy_dtype(pandas_dtype.type)\n\u001b[32m    803\u001b[39m ]\n\u001b[32m    804\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m bad_pandas_dtypes:\n\u001b[32m--> \u001b[39m\u001b[32m805\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    806\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpandas dtypes must be int, float or bool.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFields with bad pandas dtypes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(bad_pandas_dtypes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    807\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: pandas dtypes must be int, float or bool.\nFields with bad pandas dtypes: datetime: object, name: object, datetime.1: object, preciptype: object, conditions: object, icon: object, stations: object"
     ]
    }
   ],
   "source": [
    "# 2ï¸âƒ£ TUNING HYPERPARAMETERS LIGHTGBM Vá»šI OPTUNA\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from optuna.trial import Trial\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import yaml\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ”§ Báº®T Äáº¦U TUNING HYPERPARAMETERS LIGHTGBM Vá»šI OPTUNA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load dá»¯ liá»‡u náº¿u chÆ°a load\n",
    "if 'X_train' not in locals():\n",
    "    print(\"\\nğŸ“Š Äang táº£i dá»¯ liá»‡u...\")\n",
    "    data_dir = \"../processed_data\"\n",
    "    \n",
    "    try:\n",
    "        X_train = pd.read_csv(f\"{data_dir}/data_train.csv\")\n",
    "        X_val = pd.read_csv(f\"{data_dir}/data_val.csv\")\n",
    "        X_test = pd.read_csv(f\"{data_dir}/data_test.csv\")\n",
    "        \n",
    "        # TÃ¡ch features vÃ  target\n",
    "        y_train = X_train.iloc[:, -1]\n",
    "        X_train = X_train.iloc[:, :-1]\n",
    "        \n",
    "        y_val = X_val.iloc[:, -1]\n",
    "        X_val = X_val.iloc[:, :-1]\n",
    "        \n",
    "        y_test = X_test.iloc[:, -1]\n",
    "        X_test = X_test.iloc[:, :-1]\n",
    "        \n",
    "        # Loáº¡i bá» cÃ¡c cá»™t non-numeric\n",
    "        print(\"ğŸ” Loáº¡i bá» cÃ¡c cá»™t khÃ´ng pháº£i sá»‘...\")\n",
    "        numeric_cols = X_train.select_dtypes(include=[np.number]).columns\n",
    "        X_train = X_train[numeric_cols].astype(np.float32)\n",
    "        X_val = X_val[numeric_cols].astype(np.float32)\n",
    "        X_test = X_test[numeric_cols].astype(np.float32)\n",
    "        \n",
    "        # Convert target to float\n",
    "        y_train = y_train.astype(np.float32)\n",
    "        y_val = y_val.astype(np.float32)\n",
    "        y_test = y_test.astype(np.float32)\n",
    "        \n",
    "        # Xá»­ lÃ½ NaN values\n",
    "        print(f\"Train NaN trÆ°á»›c: {X_train.isna().sum().sum()}\")\n",
    "        X_train = X_train.fillna(0)\n",
    "        X_val = X_val.fillna(0)\n",
    "        X_test = X_test.fillna(0)\n",
    "        \n",
    "        y_train = y_train.fillna(0)\n",
    "        y_val = y_val.fillna(0)\n",
    "        y_test = y_test.fillna(0)\n",
    "        print(f\"Train NaN sau: {X_train.isna().sum().sum()}\")\n",
    "        \n",
    "        print(f\"âœ… Train shape: {X_train.shape}\")\n",
    "        print(f\"âœ… Val shape: {X_val.shape}\")\n",
    "        print(f\"âœ… Test shape: {X_test.shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Lá»—i táº£i dá»¯ liá»‡u: {e}\")\n",
    "        print(\"ğŸ’¡ Táº¡o dá»¯ liá»‡u giáº£ Ä‘á»‹nh cho demo...\")\n",
    "        \n",
    "        # Táº¡o dá»¯ liá»‡u giáº£ Ä‘á»‹nh\n",
    "        from sklearn.datasets import make_regression\n",
    "        X, y = make_regression(n_samples=1000, n_features=20, noise=10, random_state=42)\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "        \n",
    "        X_train = pd.DataFrame(X_train, columns=[f'feature_{i}' for i in range(X.shape[1])]).astype(np.float32)\n",
    "        X_val = pd.DataFrame(X_val, columns=[f'feature_{i}' for i in range(X.shape[1])]).astype(np.float32)\n",
    "        X_test = pd.DataFrame(X_test, columns=[f'feature_{i}' for i in range(X.shape[1])]).astype(np.float32)\n",
    "        y_train = pd.Series(y_train).astype(np.float32)\n",
    "        y_val = pd.Series(y_val).astype(np.float32)\n",
    "        y_test = pd.Series(y_test).astype(np.float32)\n",
    "\n",
    "def objective(trial: Trial):\n",
    "    \"\"\"\n",
    "    HÃ m objective Ä‘á»ƒ Optuna tá»‘i Æ°u hÃ³a\n",
    "    \"\"\"\n",
    "    # Äá»‹nh nghÄ©a khÃ´ng gian hyperparameter\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'mse',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 0.1),\n",
    "        'random_state': 42,\n",
    "        'verbose': -1,\n",
    "    }\n",
    "    \n",
    "    # Táº¡o LightGBM dataset\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    \n",
    "    # Train model vá»›i early stopping\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=100,\n",
    "        valid_sets=[lgb.Dataset(X_val, label=y_val)],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=20),\n",
    "            lgb.log_evaluation(period=0)  # Táº¯t log\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # ÄÃ¡nh giÃ¡ trÃªn validation set\n",
    "    y_pred = model.predict(X_val)\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "# Táº¡o study vá»›i Optuna\n",
    "print(\"\\nğŸ“Š Báº¯t Ä‘áº§u tuning vá»›i 50 trials...\")\n",
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=42)\n",
    ")\n",
    "\n",
    "# Cháº¡y optimization\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "# 3ï¸âƒ£ Hiá»ƒn thá»‹ káº¿t quáº£\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… HOÃ€N THÃ€NH TUNING!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Best trial\n",
    "best_trial = study.best_trial\n",
    "print(f\"\\nğŸ† Best Trial: {best_trial.number}\")\n",
    "print(f\"ğŸ“Š Best MSE: {best_trial.value:.6f}\")\n",
    "print(f\"\\nğŸ“ Best Hyperparameters:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# 4ï¸âƒ£ Train mÃ´ hÃ¬nh final vá»›i best hyperparameters\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸš€ TRAIN MÃ” HÃŒNH FINAL Vá»šI BEST HYPERPARAMETERS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "best_params['objective'] = 'regression'\n",
    "best_params['metric'] = 'mse'\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "final_model = lgb.train(\n",
    "    best_params,\n",
    "    train_data,\n",
    "    num_boost_round=200,\n",
    "    valid_sets=[lgb.Dataset(X_val, label=y_val)],\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=20),\n",
    "        lgb.log_evaluation(period=20)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 5ï¸âƒ£ ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š ÄÃNH GIÃ MÃ” HÃŒNH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train evaluation\n",
    "y_train_pred = final_model.predict(X_train)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(f\"\\nğŸƒ Train Metrics:\")\n",
    "print(f\"  MSE:  {train_mse:.6f}\")\n",
    "print(f\"  MAE:  {train_mae:.6f}\")\n",
    "print(f\"  RÂ²:   {train_r2:.6f}\")\n",
    "\n",
    "# Val evaluation\n",
    "y_val_pred = final_model.predict(X_val)\n",
    "val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"\\nâœ”ï¸ Val Metrics:\")\n",
    "print(f\"  MSE:  {val_mse:.6f}\")\n",
    "print(f\"  MAE:  {val_mae:.6f}\")\n",
    "print(f\"  RÂ²:   {val_r2:.6f}\")\n",
    "\n",
    "# Test evaluation\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"\\nğŸ¯ Test Metrics:\")\n",
    "print(f\"  MSE:  {test_mse:.6f}\")\n",
    "print(f\"  MAE:  {test_mae:.6f}\")\n",
    "print(f\"  RÂ²:   {test_r2:.6f}\")\n",
    "\n",
    "# 6ï¸âƒ£ LÆ°u mÃ´ hÃ¬nh\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ’¾ LÆ¯U MÃ” HÃŒNH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_path = \"lightgbm_best_model.pkl\"\n",
    "joblib.dump(final_model, model_path)\n",
    "print(f\"âœ… MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u: {model_path}\")\n",
    "\n",
    "# LÆ°u best hyperparameters\n",
    "params_path = \"lightgbm_best_params.yaml\"\n",
    "with open(params_path, 'w') as f:\n",
    "    yaml.dump(best_params, f, default_flow_style=False)\n",
    "print(f\"âœ… Best hyperparameters Ä‘Ã£ Ä‘Æ°á»£c lÆ°u: {params_path}\")\n",
    "\n",
    "print(\"\\nâœ… QuÃ¡ trÃ¬nh tuning hoÃ n thÃ nh!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
